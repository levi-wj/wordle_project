{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "from textstat import textstat # Used to get reading level\n",
    "from wordfreq import zipf_frequency # Used to get word frequency\n",
    "import nltk # Used to classify words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Contest number</th>\n",
       "      <th>Word</th>\n",
       "      <th>Number of reported results</th>\n",
       "      <th>Number in hard mode</th>\n",
       "      <th>1 try</th>\n",
       "      <th>2 tries</th>\n",
       "      <th>3 tries</th>\n",
       "      <th>4 tries</th>\n",
       "      <th>5 tries</th>\n",
       "      <th>6 tries</th>\n",
       "      <th>7 or more tries (X)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/31/2022</td>\n",
       "      <td>560</td>\n",
       "      <td>manly</td>\n",
       "      <td>20380</td>\n",
       "      <td>1899</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>559</td>\n",
       "      <td>molar</td>\n",
       "      <td>21204</td>\n",
       "      <td>1973</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>558</td>\n",
       "      <td>havoc</td>\n",
       "      <td>20001</td>\n",
       "      <td>1919</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>30</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>557</td>\n",
       "      <td>impel</td>\n",
       "      <td>20160</td>\n",
       "      <td>1937</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>40</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>556</td>\n",
       "      <td>condo</td>\n",
       "      <td>20879</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>29</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Contest number   Word  Number of reported results  \\\n",
       "0  12/31/2022             560  manly                       20380   \n",
       "1  12/30/2022             559  molar                       21204   \n",
       "2  12/29/2022             558  havoc                       20001   \n",
       "3  12/28/2022             557  impel                       20160   \n",
       "4  12/27/2022             556  condo                       20879   \n",
       "\n",
       "   Number in hard mode  1 try  2 tries  3 tries  4 tries  5 tries  6 tries  \\\n",
       "0                 1899      0        2       17       37       29       12   \n",
       "1                 1973      0        4       21       38       26        9   \n",
       "2                 1919      0        2       16       38       30       12   \n",
       "3                 1937      0        3       21       40       25        9   \n",
       "4                 2012      0        2       17       35       29       14   \n",
       "\n",
       "   7 or more tries (X)  \n",
       "0                    2  \n",
       "1                    1  \n",
       "2                    2  \n",
       "3                    1  \n",
       "4                    3  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Problem_C_Data_Wordle.csv', encoding='latin1');\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix the typo? And special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Replace the Word 'marxh' in the dataframe with 'march'\n",
    "df['Word'] = df['Word'].replace('marxh', 'march')\n",
    "df['Word'] = df['Word'].replace('naï¿½ve', 'naive')\n",
    "\n",
    "print(len(df[df['Word'] == 'march']))\n",
    "print(len(df[df['Word'] == 'naive']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop data that we can't use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Word</th>\n",
       "      <th>Number of reported results</th>\n",
       "      <th>Number in hard mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/31/2022</td>\n",
       "      <td>manly</td>\n",
       "      <td>20380</td>\n",
       "      <td>1899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>molar</td>\n",
       "      <td>21204</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>havoc</td>\n",
       "      <td>20001</td>\n",
       "      <td>1919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>impel</td>\n",
       "      <td>20160</td>\n",
       "      <td>1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>condo</td>\n",
       "      <td>20879</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Word  Number of reported results  Number in hard mode\n",
       "0  12/31/2022  manly                       20380                 1899\n",
       "1  12/30/2022  molar                       21204                 1973\n",
       "2  12/29/2022  havoc                       20001                 1919\n",
       "3  12/28/2022  impel                       20160                 1937\n",
       "4  12/27/2022  condo                       20879                 2012"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = df.drop(['Contest number', 'Number of reported results', 'Number in hard mode'], axis=1)\n",
    "df = df.drop(columns=['Contest number', '1 try', '2 tries', '3 tries', '4 tries', '5 tries', '6 tries', '7 or more tries (X)'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create feature columns for word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\leviw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Word</th>\n",
       "      <th>Number of reported results</th>\n",
       "      <th>Number in hard mode</th>\n",
       "      <th>Vowel consonant ratio</th>\n",
       "      <th>Scrabble score</th>\n",
       "      <th>Letter repetition</th>\n",
       "      <th>Frequency score</th>\n",
       "      <th>Words 1 away</th>\n",
       "      <th>Words 2 away</th>\n",
       "      <th>...</th>\n",
       "      <th>q</th>\n",
       "      <th>r</th>\n",
       "      <th>s</th>\n",
       "      <th>t</th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "      <th>w</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12/31/2022</td>\n",
       "      <td>manly</td>\n",
       "      <td>20380</td>\n",
       "      <td>1899</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3.66</td>\n",
       "      <td>8</td>\n",
       "      <td>149</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12/30/2022</td>\n",
       "      <td>molar</td>\n",
       "      <td>21204</td>\n",
       "      <td>1973</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2.99</td>\n",
       "      <td>12</td>\n",
       "      <td>91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12/29/2022</td>\n",
       "      <td>havoc</td>\n",
       "      <td>20001</td>\n",
       "      <td>1919</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/28/2022</td>\n",
       "      <td>impel</td>\n",
       "      <td>20160</td>\n",
       "      <td>1937</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>2.36</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/27/2022</td>\n",
       "      <td>condo</td>\n",
       "      <td>20879</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3.63</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   Word  Number of reported results  Number in hard mode  \\\n",
       "0  12/31/2022  manly                       20380                 1899   \n",
       "1  12/30/2022  molar                       21204                 1973   \n",
       "2  12/29/2022  havoc                       20001                 1919   \n",
       "3  12/28/2022  impel                       20160                 1937   \n",
       "4  12/27/2022  condo                       20879                 2012   \n",
       "\n",
       "   Vowel consonant ratio  Scrabble score  Letter repetition  Frequency score  \\\n",
       "0               0.250000              10                  0             3.66   \n",
       "1               0.666667               7                  0             2.99   \n",
       "2               0.666667              13                  0             3.50   \n",
       "3               0.666667               9                  0             2.36   \n",
       "4               0.666667               8                  1             3.63   \n",
       "\n",
       "   Words 1 away  Words 2 away  ...  q  r  s  t  u  v  w  x  y  z  \n",
       "0             8           149  ...  0  0  0  0  0  0  0  0  1  0  \n",
       "1            12            91  ...  0  1  0  0  0  0  0  0  0  0  \n",
       "2             0            15  ...  0  0  0  0  0  1  0  0  0  0  \n",
       "3             1            19  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "4             9            72  ...  0  0  0  0  0  0  0  0  0  0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def vowels_consonants_ratio(word):\n",
    "    vowels = 'aeiou'\n",
    "    word = word.lower()\n",
    "    num_vowels = sum(1 for char in word if char in vowels)\n",
    "    num_consonants = sum(1 for char in word if char.isalpha() and char not in vowels)\n",
    "    if num_consonants == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    return num_vowels / num_consonants\n",
    "\n",
    "# Scrabble letter values\n",
    "scrabble_values = {\n",
    "    'a': 1,  'b': 3,  'c': 3,  'd': 2,  'e': 1,  'f': 4,  'g': 2,  'h': 4,\n",
    "    'i': 1,  'j': 8,  'k': 5,  'l': 1,  'm': 3,  'n': 1,  'o': 1,  'p': 3,\n",
    "    'q':10,  'r': 1,  's': 1,  't': 1,  'u': 1,  'v': 4,  'w': 4,  'x': 8,\n",
    "    'y': 4,  'z':10\n",
    "}\n",
    "\n",
    "def scrabble_score(word):\n",
    "    return sum(scrabble_values.get(char.lower(), 0) for char in word)\n",
    "\n",
    "def letter_repetition_count(word):\n",
    "    return len(word) - len(set(word.lower()))\n",
    "\n",
    "def create_sentence(word):\n",
    "    return f\"The word is {word}.\"\n",
    "\n",
    "def frequency_score(word):\n",
    "    return zipf_frequency(word.lower(), 'en')\n",
    "\n",
    "words_df = pd.read_csv('wordsv21.csv')\n",
    "word_list = words_df['word'].tolist()\n",
    "def word_permutations(word, num_diff_letters):\n",
    "    count = 0\n",
    "    for w in word_list:\n",
    "        if sum(c1 != c2 for c1, c2 in zip(word.lower(), w.lower())) == num_diff_letters:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "def word_category(word):\n",
    "    return nltk.pos_tag([word])[0][1]\n",
    "\n",
    "common_bigrams = set(['th', 'he', 'in', 'er', 'an', 're', 'ed', 'on', 'es', 'st'])\n",
    "def common_bigrams_count(word):\n",
    "    word = word.lower()\n",
    "    return sum(1 for i in range(len(word)-1) if word[i:i+2] in common_bigrams)\n",
    "\n",
    "def add_letter_count_features(my_df):\n",
    "    # Get a list of all lowercase letters\n",
    "    letters = list(string.ascii_lowercase)\n",
    "    \n",
    "    # Initialize new columns in the DataFrame for each letter with zeros\n",
    "    for letter in letters:\n",
    "        my_df[letter] = 0\n",
    "\n",
    "    # Function to count letters in a word\n",
    "    def count_letters(word):\n",
    "        word = word.lower()\n",
    "        letter_counts = {}\n",
    "        for letter in letters:\n",
    "            letter_counts[letter] = word.count(letter)\n",
    "        return letter_counts\n",
    "\n",
    "    for idx, word in my_df['Word'].items():\n",
    "        letter_counts = count_letters(word)\n",
    "        for letter, count in letter_counts.items():\n",
    "            my_df.at[idx, letter] = count\n",
    "\n",
    "    return my_df\n",
    "\n",
    "def create_features(my_df):\n",
    "    my_df['Vowel consonant ratio'] = my_df['Word'].apply(vowels_consonants_ratio)\n",
    "    my_df['Scrabble score'] = my_df['Word'].apply(scrabble_score)\n",
    "    my_df['Letter repetition'] = my_df['Word'].apply(letter_repetition_count)\n",
    "    my_df['Frequency score'] = my_df['Word'].apply(frequency_score)\n",
    "    my_df['Words 1 away'] = my_df['Word'].apply(lambda row: word_permutations(row, 1)) # Words only one letter permutation away\n",
    "    my_df['Words 2 away'] = my_df['Word'].apply(lambda row: word_permutations(row, 2)) # Words only one letter permutation away\n",
    "    my_df['Word category'] = my_df['Word'].apply(word_category)\n",
    "    my_df['Common bigrams'] = my_df['Word'].apply(common_bigrams_count)\n",
    "    my_df['Flesch_Reading_Ease'] = my_df['Word'].apply(lambda x: textstat.flesch_reading_ease(create_sentence(x)))\n",
    "    my_df['Dale_Chall_Readability_Score'] = my_df['Word'].apply(lambda x: textstat.dale_chall_readability_score(create_sentence(x)))\n",
    "    my_df['Difficult_Words'] = my_df['Word'].apply(lambda x: textstat.difficult_words(create_sentence(x)))\n",
    "    # my_df['Flesch_Kincaid_Grade'] = my_df['Word'].apply(lambda x: textstat.flesch_kincaid_grade(create_sentence(x)))\n",
    "\n",
    "    my_df = pd.get_dummies(my_df, columns=['Word category'])\n",
    "    my_df = add_letter_count_features(my_df)\n",
    "    return my_df\n",
    "\n",
    "df = create_features(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69    2\n",
       "Name: Letter repetition, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Word'] == 'mummy']['Letter repetition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform date column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Word', 'Number of reported results', 'Number in hard mode',\n",
      "       'Vowel consonant ratio', 'Scrabble score', 'Letter repetition',\n",
      "       'Frequency score', 'Words 1 away', 'Words 2 away', 'Common bigrams',\n",
      "       ...\n",
      "       'Day_22', 'Day_23', 'Day_24', 'Day_25', 'Day_26', 'Day_27', 'Day_28',\n",
      "       'Day_29', 'Day_30', 'Day_31'],\n",
      "      dtype='object', length=101)\n"
     ]
    }
   ],
   "source": [
    "def encode_date(my_df):\n",
    "  my_df['Date'] = pd.to_datetime(my_df['Date'])\n",
    "\n",
    "  my_df['Month'] = my_df['Date'].dt.month\n",
    "  my_df['Day of week'] = my_df['Date'].dt.dayofweek  # Monday=0, Sunday=6\n",
    "  my_df['Year'] = my_df['Date'].dt.year\n",
    "  my_df['Day'] = my_df['Date'].dt.day\n",
    "\n",
    "  my_df = pd.get_dummies(my_df, columns=['Month', 'Day of week', 'Day'])\n",
    "  my_df = my_df.drop(['Date'], axis=1)\n",
    "\n",
    "  return my_df\n",
    "\n",
    "df = encode_date(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 20837.43202060057\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=['Number of reported results', 'Number in hard mode', 'Word'], axis=1)\n",
    "y = df[['Number of reported results', 'Number in hard mode']]\n",
    "\n",
    "# Save features for later encoding\n",
    "feature_columns = X.columns.tolist()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=41)\n",
    "\n",
    "# Initialize the model\n",
    "xgb = XGBRegressor(objective='reg:squarederror', eval_metric='rmse')\n",
    "\n",
    "# Wrap the model with MultiOutputRegressor\n",
    "multi_output_model = MultiOutputRegressor(xgb)\n",
    "\n",
    "# Train the model\n",
    "multi_output_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the distribution\n",
    "y_pred = multi_output_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(f'RMSE: {root_mean_squared_error(y_test, y_pred)}')\n",
    "\n",
    "# r2_values = {}\n",
    "# for i, target in enumerate(y.columns):\n",
    "#     r2_values[target] = r2_score(y_test.iloc[:, i], y_pred[:, i])\n",
    "#     print(f\"R-squared for {target}: {r2_values[target]:.4f}\")\n",
    "\n",
    "# mean_r2 = np.mean(list(r2_values.values()))\n",
    "# print(f\"Mean R-squared: {mean_r2:.4f}\")\n",
    "\n",
    "# test_length = len(y_pred)\n",
    "\n",
    "# for key in r2_values:\n",
    "#     r2_values[key] = (1 - r2_values[key]) * (test_length - 1) / (test_length - len(df.columns) - 1)\n",
    "#     print(r2_values[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Month_2</th>\n",
       "      <td>4.736609e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_1</th>\n",
       "      <td>2.356944e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_3</th>\n",
       "      <td>1.447512e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_4</th>\n",
       "      <td>5.851172e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_8</th>\n",
       "      <td>1.365276e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_5</th>\n",
       "      <td>1.289475e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_14</th>\n",
       "      <td>8.091037e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>6.461823e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f</th>\n",
       "      <td>6.165216e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_15</th>\n",
       "      <td>4.769026e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_11</th>\n",
       "      <td>4.587606e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_6</th>\n",
       "      <td>4.574775e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_7</th>\n",
       "      <td>2.424652e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_12</th>\n",
       "      <td>2.285595e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dale_Chall_Readability_Score</th>\n",
       "      <td>2.028502e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_NN</th>\n",
       "      <td>1.277452e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_1</th>\n",
       "      <td>1.098067e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_11</th>\n",
       "      <td>9.431568e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Difficult_Words</th>\n",
       "      <td>9.230540e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_10</th>\n",
       "      <td>7.624729e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_26</th>\n",
       "      <td>7.383917e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p</th>\n",
       "      <td>7.159897e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_4</th>\n",
       "      <td>6.844494e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>6.716202e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_28</th>\n",
       "      <td>6.304611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Words 2 away</th>\n",
       "      <td>6.058913e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_4</th>\n",
       "      <td>5.662991e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>5.520275e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>5.379611e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>5.373124e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_JJ</th>\n",
       "      <td>4.943577e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>4.917621e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Common bigrams</th>\n",
       "      <td>4.569140e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_5</th>\n",
       "      <td>4.316708e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>4.210939e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Letter repetition</th>\n",
       "      <td>4.086926e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Words 1 away</th>\n",
       "      <td>3.880823e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_27</th>\n",
       "      <td>3.496420e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>3.292267e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2.994695e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_9</th>\n",
       "      <td>2.716669e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l</th>\n",
       "      <td>2.660396e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2.483828e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_VBN</th>\n",
       "      <td>2.390012e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_30</th>\n",
       "      <td>2.343916e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_1</th>\n",
       "      <td>2.238632e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>2.230618e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_2</th>\n",
       "      <td>2.150120e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1.994658e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Flesch_Reading_Ease</th>\n",
       "      <td>1.914452e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k</th>\n",
       "      <td>1.900290e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency score</th>\n",
       "      <td>1.499891e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_5</th>\n",
       "      <td>1.460129e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_6</th>\n",
       "      <td>1.422798e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_31</th>\n",
       "      <td>1.289164e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>1.151152e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.125367e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scrabble score</th>\n",
       "      <td>1.087697e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>1.054862e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vowel consonant ratio</th>\n",
       "      <td>7.864124e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_3</th>\n",
       "      <td>6.694106e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>w</th>\n",
       "      <td>6.574549e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_7</th>\n",
       "      <td>6.479894e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>5.652315e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_9</th>\n",
       "      <td>5.556388e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_6</th>\n",
       "      <td>5.077160e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_10</th>\n",
       "      <td>3.616690e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_25</th>\n",
       "      <td>2.566775e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month_8</th>\n",
       "      <td>2.241891e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_24</th>\n",
       "      <td>2.157594e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_20</th>\n",
       "      <td>1.594278e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_3</th>\n",
       "      <td>1.424711e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_29</th>\n",
       "      <td>1.243591e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_13</th>\n",
       "      <td>6.550123e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_19</th>\n",
       "      <td>5.710061e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_2</th>\n",
       "      <td>4.198178e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day of week_0</th>\n",
       "      <td>3.504782e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_16</th>\n",
       "      <td>3.437643e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>3.304920e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_18</th>\n",
       "      <td>2.887920e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_21</th>\n",
       "      <td>6.327857e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_22</th>\n",
       "      <td>5.257588e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>4.102785e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q</th>\n",
       "      <td>2.988433e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>j</th>\n",
       "      <td>1.397120e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_23</th>\n",
       "      <td>5.274864e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_17</th>\n",
       "      <td>2.774981e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_VBG</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_PRP$</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_VB</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_NNS</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_MD</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_JJR</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_RB</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word category_DT</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day_12</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Importance\n",
       "Month_2                       4.736609e-01\n",
       "Month_1                       2.356944e-01\n",
       "Month_3                       1.447512e-01\n",
       "Month_4                       5.851172e-02\n",
       "Day_8                         1.365276e-02\n",
       "Month_5                       1.289475e-02\n",
       "Day_14                        8.091037e-03\n",
       "g                             6.461823e-03\n",
       "f                             6.165216e-03\n",
       "Day_15                        4.769026e-03\n",
       "Day_11                        4.587606e-03\n",
       "Month_6                       4.574775e-03\n",
       "Month_7                       2.424652e-03\n",
       "Month_12                      2.285595e-03\n",
       "Dale_Chall_Readability_Score  2.028502e-03\n",
       "Word category_NN              1.277452e-03\n",
       "Day of week_1                 1.098067e-03\n",
       "Month_11                      9.431568e-04\n",
       "Difficult_Words               9.230540e-04\n",
       "Month_10                      7.624729e-04\n",
       "Day_26                        7.383917e-04\n",
       "p                             7.159897e-04\n",
       "Day of week_4                 6.844494e-04\n",
       "v                             6.716202e-04\n",
       "Day_28                        6.304611e-04\n",
       "Words 2 away                  6.058913e-04\n",
       "Day_4                         5.662991e-04\n",
       "u                             5.520275e-04\n",
       "h                             5.379611e-04\n",
       "c                             5.373124e-04\n",
       "Word category_JJ              4.943577e-04\n",
       "r                             4.917621e-04\n",
       "Common bigrams                4.569140e-04\n",
       "Day of week_5                 4.316708e-04\n",
       "d                             4.210939e-04\n",
       "Letter repetition             4.086926e-04\n",
       "Words 1 away                  3.880823e-04\n",
       "Day_27                        3.496420e-04\n",
       "e                             3.292267e-04\n",
       "b                             2.994695e-04\n",
       "Month_9                       2.716669e-04\n",
       "l                             2.660396e-04\n",
       "t                             2.483828e-04\n",
       "Word category_VBN             2.390012e-04\n",
       "Day_30                        2.343916e-04\n",
       "Day_1                         2.238632e-04\n",
       "n                             2.230618e-04\n",
       "Day_2                         2.150120e-04\n",
       "i                             1.994658e-04\n",
       "Flesch_Reading_Ease           1.914452e-04\n",
       "k                             1.900290e-04\n",
       "Frequency score               1.499891e-04\n",
       "Day_5                         1.460129e-04\n",
       "Day_6                         1.422798e-04\n",
       "Day_31                        1.289164e-04\n",
       "y                             1.151152e-04\n",
       "a                             1.125367e-04\n",
       "Scrabble score                1.087697e-04\n",
       "o                             1.054862e-04\n",
       "Vowel consonant ratio         7.864124e-05\n",
       "Day_3                         6.694106e-05\n",
       "w                             6.574549e-05\n",
       "Day_7                         6.479894e-05\n",
       "s                             5.652315e-05\n",
       "Day_9                         5.556388e-05\n",
       "Day of week_6                 5.077160e-05\n",
       "Day_10                        3.616690e-05\n",
       "Day_25                        2.566775e-05\n",
       "Month_8                       2.241891e-05\n",
       "Day_24                        2.157594e-05\n",
       "Day_20                        1.594278e-05\n",
       "Day of week_3                 1.424711e-05\n",
       "Day_29                        1.243591e-05\n",
       "Day_13                        6.550123e-06\n",
       "Day_19                        5.710061e-06\n",
       "Day of week_2                 4.198178e-06\n",
       "Day of week_0                 3.504782e-06\n",
       "Day_16                        3.437643e-06\n",
       "m                             3.304920e-06\n",
       "Day_18                        2.887920e-06\n",
       "Day_21                        6.327857e-07\n",
       "Day_22                        5.257588e-07\n",
       "z                             4.102785e-07\n",
       "q                             2.988433e-07\n",
       "j                             1.397120e-07\n",
       "Day_23                        5.274864e-08\n",
       "Day_17                        2.774981e-08\n",
       "Year                          0.000000e+00\n",
       "Word category_VBG             0.000000e+00\n",
       "Word category_PRP$            0.000000e+00\n",
       "Word category_VB              0.000000e+00\n",
       "x                             0.000000e+00\n",
       "Word category_NNS             0.000000e+00\n",
       "Word category_MD              0.000000e+00\n",
       "Word category_JJR             0.000000e+00\n",
       "Word category_RB              0.000000e+00\n",
       "Word category_DT              0.000000e+00\n",
       "Day_12                        0.000000e+00"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the model feature importances\n",
    "importances = multi_output_model.estimators_[0].feature_importances_\n",
    "importances_df = pd.DataFrame(importances, index=X.columns, columns=['Importance'])\n",
    "importances_df = importances_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict for Eerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[229989.6     9957.176]]\n"
     ]
    }
   ],
   "source": [
    "eerie_df = pd.DataFrame({\n",
    "  'Date': '2023-03-01',\n",
    "  'Word': 'EERIE'\n",
    "}, index=[0])\n",
    "\n",
    "eerie_df = create_features(eerie_df)\n",
    "eerie_df = encode_date(eerie_df)\n",
    "eerie_df = eerie_df.drop(columns=['Word'], axis=1)\n",
    "\n",
    "eerie_df = eerie_df.reindex(columns=feature_columns, fill_value=0)\n",
    "\n",
    "output = multi_output_model.predict(eerie_df)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
